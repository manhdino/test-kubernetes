Kubernetes: 
+ Kubernetes là một nền tảng để quản lý, mở rộng các ứng dụng hoạt động dựa trên containers, giúp thuận lợi trong việc cấu hình và tự động triển khai ứng dụng một cách linh hoạt và tin cậy.
+ Kubernetes giúp chúng ta điều phối các container, nó đảm bảo tất cả các containers được lên lịch chạy trên các server(physical machine hoặc virtual machine).
+ Kubernetes còn giúp ta theo dõi hoạt động của các container, khi một container nào đó gặp lõi hoặc dừng hoạt động thì kubernetes sẽ tự động thay thế container đó.
+ Pod
   + Pod là đơn vị nhỏ nhất trong k8s chứa một hoặc nhiều container liên quan đến nhau.
   + Hay hiểu đơn giản là pod sẽ tạo ra môi trường chạy các container. 
   + Mỗi pod sẽ sở hữu một internal Ip riêng và có thể giao tiếp với nhau.
   + Địa chỉ IP này sẽ được thay đổi khi các pod được khởi tạo lại (re-creation). 
   + Thông thường một ứng dụng sẽ được chạy trên một pod.
   + Vì địa chỉ IP của pod được thay đổi mỗi khi được khởi tạo lại nên giả sử container db của ta bị lỗi khiến pod chứa 2 container db và app phải tiến hành khởi tạo lại 
   để thay thế cái cũ thì lúc này 2 pod sẽ bị mất kết nối.
    -->  Chính vì vậy ta sẽ có tiếp một khái niệm mới là service.
+ Service
   + Service được xác định dựa trên label, đại diện cho một entry point để truy cập vào ứng dụng.
   + Mỗi service có địa chỉ IP và port không đổi. 
   + Client có thể kết nối đến các IP và port của service, sau đó sẽ được điều hướng đến các pod để xử lý.
   +  Quan trọng hơn hết là life cycle của service và pod không liên quan quan (kết nối) với nhau nên khi một pod bị crash (hoặc chết) thì service và IP của nó vẫn tồn tại.
   +  Chúng ta có thể định nghĩa external service hoặc internal service tùy vào mục đích sử dụng. 
   + Khi browser request đến ứng dụng, lúc này ta sẽ sử dụng IP để kết nối (external service) nhưng url với những sản phẩm production sẽ có domain name 
    lúc này ta có tiếp một khái niệm là ingress.
+ Ingress
   + Ingress là thành phần dùng để điều hướng các yêu cầu trafic giao thức HTTP và HTTPS từ bên ngoài vào các dịch vụ bên trong Cluster. 
   + Request sẽ đi đến ingreass và chuyển tiếp đến các service.
+ Label
   + Label cung cấp meta data nhận dạng cho các object trong Kubernetes.
   + Label cho phép ta tổ chức và nhóm các object trong cluster. 
   + Một object có thể có nhiều label và một label có thể được gán cho nhiều object khác nhau (n-n). 
   + Ta có thể dùng label để lọc các đối tượng trong cluster một cách dễ dàng

+ ReplicaSet
  + ReplicaSet sẽ đảm bảo rằng ứng dụng của ta luôn chạy đúng loại và số lượng pod trong cluster.
  + Ví dụ như khi chạy webserver thay vì chỉ chạy 1 instance ta sẽ chạy 2 hoặc 3 instance đẻ đảm bảo ứng dụng hoạt động ổn định. 
  + Trong một trường hợp nào đó khi pod bị crash thì k8s sẽ tự động tạo lại đủ số lượng pod tùy vào ReplicaSet ta định nghĩa.

+ ConfigMap 
  + Khi cần cung cấp cấu hình trong quá trình runtime của container. 
  + Giả sử ta có ứng dụng laravel kết nới với database mysql ta cần một số config như DB_ADDRESS, DB_NAME, DB_PASSWORD, ... mà không cần can thiệp vào code. 
  + ConfigMap cung cấp dữ liệu dưới dạng key và value.

+ Secrets:
  + Cũng tương tự như ConfigMap nhưng dùng với nhưng dữ liệu nhạy cảm cần được bảo mật như API_TOKEN, DB_PASSWORD, ...
  + Sử dụng secrets cho phép ta tạo container mà không cần đóng gói dữ liệu nhảy cảm trong container. 
  + Ta có thể truyền ConfigMap và Secret thông qua mainfest file hoặc k8s API. 


Kubernetes Architecture
  + Khi deploy Kubernetes, chúng ta sẽ có một cluster.
  + Một Kubernetes cluster bao gồm một tập hợp các worker machine đợi gọi là nodes giúp ta chạy các ứng dụng đã được container hóa. 
  + Trong đó các node sẽ được cung cấp các tài nguyên như computing, memory, storage, networking.
  + Mỗi một cluster có ít nhất một worker node.
  
+ Node processes
  + Kubernetes nodes là máy ảo hay máy vật lý chạy kubernetes.
  + Các node này cần chạy Kubernetes và docker, và mỗi máy này là một docker host.
  +  Mỗi node có nhiều pod.

+ Master node
  + Master node là server điều khiển các máy worker chạy ứng dụng. Nó bao gồm 4 thành phần chính:
    + Kubernetes API Server: cung cấp API cho k8s cluster dùng để thiết lập và xác thực cấu hình cho object như pod, service, .... 
      Lập trình viên khi triển khai ứng dụng sẽ gọi đến API này.
    + Scheduler: Thành phần này lập lịch triển khai cho các ứng dụng, đặt các pod vào node dựa trên tài nguyên và điều kiện khác được định nghĩa.
    + Controler Manager: Thành phần đảm nhiệm phần quản lý các Worker, kiểm tra trạng thái các Worker sống hay chết, thực hiện những thay đổi đối với cluster sao cho phù hợp.
    + Etcd: cơ sở dữ liệu của Kubernetes, tất cả các thông tin của Kubernetes được lưu trữ ở đây.

+ Worker node: là server để chạy các ứng dụng. Nó bao gồm 3 thành phần chính:
    + Kubelet: là một agent chạy trên mỗi worker có trách nghiệm giám sát giao tiếp với master node và quản lý các pod.
    + Kube-proxy: quản lý network policy trên mỗi node, chuyển tiếp, traffic tới node dựa trên policy.
    + Container runetime: phần chịu trách nghiệm chạy các container.


+ Vấn đề: các cách deploy ứng dụng phổ biến

  + Chạy thẳng ứng dụng trên server: 
     + Ở cách này chúng ta chạy ứng dụng trên server vật lý. 
     + Điểm yếu của cách deploy này là không có cách nào định nghĩa ranh giới tài nguyên giữ các ứng dụng và nó sẽ gây ra vấn đề về phân bổ tài nguyên giữa các ứng dụng. 
     + Ví dụ khi nhiều ứng dụng chạy trên cùng server vật lý, nếu có một thằng sử dụng nhiều tài nguyên hơn và cứ tăng tài nguyên nó sử dụng
      (vì ta không có giới hạn) thì những thằng còn lại sẽ có ít tài nguyên để sử dụng, khiến các ứng dụng còn lại sẽ chạy chậm
     + Để giải quyết vấn đề với cách deploy này, ta chỉ có cách là tách những thằng ứng dụng khác qua một server vật lý khác

 + Chia server ra thành các máy ảo và chạy ứng dụng trên máy ảo đó:
    + Đây là một giải pháp để giải quyết vấn đề của cách chạy thẳng ứng dụng trên server.
    + Được gọi là virtualization, nó cho phép ta chạy nhiều máy ảo (Virtual Machines - VMs) trên cùng một server vật lý, mỗi máy ảo sẽ có file system, 
    hệ điều hành (OS), share CPU riêng.
    +  Và những ứng dụng của ta sẽ chạy trong các VM này. VM được định nghĩa có giới hạn tài nguyên, do đó sẽ không xảy ra vấn để một ứng dụng sẽ chạy tốn tài nguyên 
    vượt qua giới hạn VM và ảnh hưởng tới những ứng dụng nằm trong VM khác.
    +  Điểm yếu của cách deploy này là do VM được virtualize bằng cách copy cả OS và phần cứng (hardware),
     nên một server chỉ có thể tạo một số lượng nhỏ VM (4 hoặc 5 với các server bình thường)

  + Chạy ứng dụng bằng cách sử dụng container:
    + GIống như VM, container cũng là cách để virtualize ứng dụng, nó cũng có file system, os riêng, nhưng khác với VM, container chỉ copy OS mà không copy hardware, 
    + do đó cho phép ta có thể chạy nhiều ứng dụng trên cũng server vật lý, mỗi ứng dụng sẽ có môi trường riêng của nó. 
    + Với container việc phát triển và chạy ứng dụng của ta trên các OS khác nhau rất dễ dàng.

+ Vậy kubernetes giúp ta vấn đề gì?
   + Chạy ứng dụng bằng container sẽ giúp ta rất nhiều vấn đề:
   + Hãy thử tưởng tượng nếu số container ta lên tới hơn 1000 thì làm cách nào ta biết được một container nào đó sẽ thuộc về ứng dụng nào hoặc nó thuộc project nào?
   + Nếu ta muốn tăng performance của ứng dụng bằng cách cho nó chạy bằng 2 hoặc 3 container thì làm cách nào ta có thể dẫn request người dùng tới ứng dụng mà có 2 hoặc 3 container đó,
   + Ta sẽ chỉa tới container nào? Và nếu server vật lý của chúng ta bị sự cố và không thể chạy nữa thì sao? 
+ Kubernetes sẽ giúp chúng ta giải quyết những vấn đề này nhiều nhất có thể.
   + Với kubernetes chúng ta có thể group và quản lý container theo ứng dụng và project,
   + Nó cũng cung cấp tính năng Service Discovery and Load Balancing để chúng ta có thể dẫn request của ứng dụng tới đúng container, 
   + Và cũng có tính năng giúp ứng dụng của chúng ta high available nhất có thể, khi một server vật lý gặp sự cố, nó có thể chuyển container của ta sang server vật lý khác. 
   + Ngoài ra kubernetes còn nhiều tính năng khác như: auto scale resource, auto restart application when failure, zero downtime deployment, automated rollouts and rollbacks application, 

+ Kiến trúc của Kubernetes
  + Kubernetes cluster (một cụm bao gồm một master và một hoặc nhiều worker) bao gồm 2 thành phần (component) chính:
    + Master nodes (control plane)
    + Worker nodes
  + Master nodes bao gồm 4 thành phần chính là API server, controller manager, Scheduler, Etcd 
    + API server: thành phần chính để giao tiếp với các thành phần khác
    + Controller manager: gồm nhiều controller riêng cụ thể cho từng resource và thực hiện các chứng năng cụ thể cho từng thằng resource trong kube như create pod, create deployment, v...v...
    + Scheduler: schedules ứng dụng tới node nào
    + Etcd: là một database để lưu giữ trạng thái và resource của cluster
 + Master node chỉ có nhiệm vụ control state của cluster, nó không có chạy ứng dụng trên đó, ứng dụng của chúng ta sẽ được chạy trên worker node.
 + Worker node gồm 3 thành phần chính như:
    + Container runtime (docker, rkt hoặc nền tảng khác): chạy container
    + Kubelet: giao tiếp với API server và quản lý container trong một worker node
    + Kubernetes Service Proxy (kube-proxy): quản lý network và traffic của các ứng dụng trong woker node

+ Kubernetes Pod là gì?
   + Pod là thành phần cơ bản nhất để deploy và chạy một ứng dụng, được tạo và quản lý bởi kubernetes.
   + Pod được dùng để nhóm (group) và chạy một hoặc nhiều container lại với nhau trên cùng một worker node,
    những container trong một pod sẽ chia sẻ chung tài nguyên với nhau.
   + Thông thường chỉ nên run Pod với 1 container 
 
+ Vậy tại sao là lại dùng Pod để chạy container, sao không chạy container trực tiếp? 
   + Kubernetes Pod như một wrapper của container, cung cấp cho chúng ta thêm nhiều chức năng để quản lý và chạy một container, 
   giúp container của ta chạy tốt hơn là chạy container trực tiếp, như là group tài nguyên của container, check container healthy và restart,
    chắc chắn ứng dụng trong container đã chạy thì mới gửi request tới container đó, cung cấp một số lifecycle để ta có thể thêm hành động vào Pod khi Pod chạy hoặc shutdown,...
   + Kubernetes sẽ quản lý Pod thay vì quản lý container trực tiếp


kubectl apply -f hello-kube.yml
kubectl get pod
kubectl describe pod <tên-pod>
kubectl logs <container-id>
kubectl delete pod hello-kube

+ Để test Pod, ta phải expose traffic của Pod để nó có thể nhận request trước, vì hiện tại Pod của chúng ta đang chạy trong local cluster và không có expose port ra ngoài
Có 2 cách để expose port của pod ra ngoài:
  + Service resource 
  + kubectl port-forward: kubectl port-forward pod/hello-kube 3000:3000

+ Tổ chức pod bằng cách sử dụng labels:
  + Dùng label là cách để chúng ta có thể phân chia các pod khác nhau tùy thuộc vào dự án hoặc môi trường.
  + Ví dụ công ty của chúng ta có 3 môi trường là testing, staging, production, nếu chạy pod mà không có đánh label thì sẽ rất khó để biết pod nào thuộc môi trường nào
  + Labels là một thuộc tính cặp key-value mà chúng ta gán vào resource ở phần metadata, ta có thể đặt tên key và value với tên bất kì.

kubectl get pod --show-labels
kubectl get pod -L enviroment  
kubectl get pod -l enviroment=production
kubectl delete -f hello-kube.yml


Phân chia tài nguyên của kubernetes cluster bằng cách sử dụng namespace

+ Ta đã biết cách chạy pod và dùng labels để tổ chức pod, nhưng ta chưa có phân chia tài nguyên giữa các môi trường và dự án khác nhau.
+ Ví dụ trong một dự án thì ta muốn tài nguyên của production phải nhiều hơn của testing, thì ta làm thế nào? Chúng ta sẽ dùng namespace
+ Namespace là cách để ta chia tài nguyên của cluster, và nhóm tất cả những resource liên quan lại với nhau, 
bạn có thể hiểu namespace như là một sub-cluster. 
+ Đầu tiên chúng ta list ra toàn bộ namespace: kubectl get ns
+ Ta sẽ thấy có vài namespace đã được tại bởi kube: default,kube-node-lease,kube-public,kube-system
   + default là namespace chúng ta đang làm việc với nó, khi ta sử dụng câu lệnh kubectl get để hiển thị resource, 
    nó sẽ hiểu ngầm ở bên dưới là ta muốn lấy resource của namespace mặc định. 
   + Ta có thể chỉ định resource của namespace chúng ta muốn bằng cách thêm option --namespace 

+ Namespace default là namespace mặc định cho các tài nguyên nếu bạn không chỉ định namespace cụ thể khi tạo hoặc truy vấn các tài nguyên. 
+ Điều này có nghĩa là nếu bạn không cung cấp namespace trong các lệnh kubectl, các tài nguyên sẽ được tạo ra hoặc tìm kiếm trong namespace default.
+ Khi bạn tạo các tài nguyên như Pod, Service, Deployment, hoặc ConfigMap mà không chỉ định namespace, chúng sẽ được tạo trong namespace default
+ kubectl get pods | kubectl get pods --namespace default

kube-system:
   + Namespace này chứa các tài nguyên và dịch vụ quan trọng cho việc vận hành và quản lý cluster Kubernetes.
   + Các thành phần hệ thống như kube-apiserver, kube-controller-manager, kube-scheduler, và các addon như CoreDNS hoặc các công cụ giám sát thường nằm trong namespace này.
   + Ví Dụ: Các Pod và Service quản lý các thành phần hệ thống của Kubernetes thường được triển khai ở đây.
kube-public:
  +  Namespace này được sử dụng để lưu trữ các tài nguyên có thể truy cập công khai trong cluster.
  +  Ví dụ, nó thường chứa các ConfigMap có thể được truy cập công khai bởi bất kỳ ai trong cluster.
  +  Namespace này có thể dùng để chia sẻ thông tin công khai giữa các thành phần trong cluster.
  + Ví Dụ: ConfigMap chứa thông tin về các tài nguyên công khai hoặc cấu hình có thể được truy cập bởi các thành phần khác trong cluster.
kube-node-lease:
 +  Namespace này chứa các đối tượng Lease được sử dụng để theo dõi trạng thái của các node trong cluster.
 +  Lease là một đối tượng đặc biệt giúp Kubernetes duy trì trạng thái của các node và cải thiện khả năng phục hồi.
 + Ví Dụ: Các đối tượng Lease trong namespace này giúp kubelet và các thành phần hệ thống khác theo dõi sức khỏe và trạng thái của các node.


kubectl get pod --namespace kube-system
kubectl describe pod <tên-pod> --namespace kube-system
kubectl create ns testing
kubectl create ns production
kubectl create ns staging
kubectl apply -f hello-cube.yml
kubectl get pods
kubectl get pod -n testing
kubectl delete pod hello-kube-testing -n testing
kubectl delete ns testing

+ Các Hạn Chế Khi Chạy Pod Trực Tiếp
 + Khả Năng Mở Rộng: Khi chạy Pod trực tiếp, bạn phải quản lý và theo dõi từng Pod một cách thủ công. Điều này làm giảm khả năng mở rộng và linh hoạt của hệ thống.
 + Khả Năng Tự Phục Hồi: Nếu một Pod bị lỗi hoặc bị chết, Kubernetes không tự động khởi động lại Pod đó. Điều này đòi hỏi sự can thiệp thủ công hoặc viết các script phức tạp để tự phục hồi.
 + Quản Lý Số Lượng Pod: Quản lý số lượng Pod mong muốn một cách thủ công không hiệu quả và dễ mắc lỗi. Điều này đặc biệt khó khăn khi số lượng Pod cần mở rộng hoặc thu hẹp theo tải công việc.
 + Khả Năng Kiểm Soát Tình Trạng: Không có cơ chế tự động để đảm bảo rằng số lượng Pod luôn đúng với yêu cầu. Việc này có thể dẫn đến tình trạng quá tải hoặc thiếu hụt tài nguyên.

--> Giải pháp: ReplicationControllers and other controller:
Như chúng ta đã biết pod là thành phần cơ bản nhất để deploy application, nhưng trong thực tế ta sẽ không chạy pod trực tiếp như ở trên,
vì nó sẽ gặp nhiều hạn chế, mà chúng ta sẽ tạo những resource khác như ReplicationControllers hoặc ReplicaSets, và nó sẽ tự động tạo và quản lý pod

+ ReplicationControllers(RC) là gì?
  + ReplicationControllers là một resource mà sẽ tạo và quản lý pod, và chắc chắn là số lượng pod nó quản lý không thay đổi và kept running.
  + ReplicationControllers sẽ tạo số lượng pod bằng với số ta chỉ định ở thuộc tính replicas và quản lý pod thông qua labels của pod

+ Tại sao ta nên dùng ReplicationControllers để chạy pod?
  + Chúng ta đã biết pod nó sẽ giám sát container và tự động restart lại container khi nó fail
  + Vậy trong trường hợp toàn bộ worker node(bọc ngoài Pod) của chúng ta fail thì sẽ thế nào? 
    --> Pod nó sẽ không thể chạy nữa, và application của chúng ta sẽ downtime với người dùng

+ Nếu chúng ta chạy cluster với hơn 1 worker node, RC sẽ giúp chúng ta giải quyết vấn đề này.
+ Vì RC sẽ chắc chắn rằng số lượng Pod mà nó tạo ra không thay đổi
+ Ví dụ khi ta tạo một thằng RC với số lượng replicas = 1, RC sẽ tạo 1 Pod và giám sát nó,
khi một thằng worker node die, nếu Pod của thằng RC quản lý có nằm trong worker node đó, 
thì lúc này thằng RC sẽ phát hiện ra là số lượng Pod của nó bằng 0, và nó sẽ tạo ra thằng Pod ở một worker node khác để đạt lại được số lượng 1
+ Luồng: Start --> Find Pods matching with Label Selector --> Compare Matched with Pod Count --> Too Few: Create additional Pod
                                                                |                                        |
                                                                | --> Too many: Delete Pods ------------ Start

+ Sử dụng RC để chạy Pod sẽ giúp ứng dụng của chúng ta luôn luôn availability nhất có thể. 
+ Ngoài ra ta có thể tăng performance của ứng dụng bằng cách chỉ định số lượng replicas trong RC để RC tạo ra nhiều pod chạy cùng một version của ứng dụng.
+ Ví dụ ta có một webservice, nếu ta chỉ deploy một pod để chạy ứng dụng, thì ta chỉ có 1 container để xử lý request của user,
nhưng nếu ta dùng RC và chỉ định replicas = 3, ta sẽ có 3 pod chạy 3 container của ứng dụng, và request của user sẽ được gửi tới 1 trong 3 pod này,
giúp quá trình xử lý của chúng ta tăng gấp 3 lần

Tại Sao Cần Nhiều Pod?
Tăng Tính Sẵn Sàng (Availability):
  + Khi chỉ có một Pod, nếu Pod đó gặp sự cố (chết, lỗi, hoặc bị ngừng hoạt động), toàn bộ dịch vụ của bạn sẽ ngừng hoạt động. 
  + Sử dụng RC hoặc ReplicaSet với nhiều Pod giúp đảm bảo rằng luôn có sẵn một số lượng Pod nhất định để xử lý yêu cầu.
Cải Thiện Hiệu Suất (Performance):
  + Với nhiều Pod, bạn có thể phân tán tải giữa các Pod, giúp tăng khả năng xử lý đồng thời và giảm độ trễ. 
  + Điều này đặc biệt quan trọng đối với các ứng dụng web hoặc các dịch vụ cần xử lý nhiều yêu cầu cùng lúc.

+ Cấu trúc của một file config RC sẽ gồm 3 phần chính như sau:
  + label selector: sẽ chỉ định pod nào sẽ được RC giám sát
  + replica count: số lượng pod sẽ được tạo
  + pod template: config của pod sẽ được tạo
kubectl apply -f hello-rc.yml
kubectl get rc  # Nếu số lượng ở cột READY bằng với số lượng DESIRED thì chúng ta đã chạy RC thành công
kubectl get pod # tên của pod được tạo ra bởi RC sẽ theo kiểu <replicationcontroller name>-<random>
kubectl delete pod hello-rc-c6l8k
kubectl get pod # Auto tạo 1 Pod mới

Thay đổi template của pod
Bạn có thể thay đổi template của pod và cập nhật lại RC, nhưng nó sẽ không apply cho những thằng pod hiện tại, 
muốn pod của bạn cập nhật template mới, bạn phải xóa hết pod để RC tạo ra pod mới, hoặc xóa RC và tạo lại
Khi  xóa RC thì những thằng pod nó quản lý cũng sẽ bị xóa theo

kubectl delete rc hello-rc

ReplicaSets(RS):
 + Đây là một resource tương tự như RC, nhưng nó là một phiên bản mới hơn của RC và sẽ được sử dụng để thay thế RC. 
 + Chúng ta sẽ dùng ReplicaSets (RS) để deploy pod thay vì dùng RC
 + RS và RC sẽ hoạt động tương tự nhau. Nhưng RS linh hoạt hơn ở phần label selector, trong khi label selector 
 thằng RC chỉ có thể chọn pod mà hoàn toàn giống với label nó chỉ định, thì thằng RS sẽ cho phép dùng một số expressions hoặc matching để chọn pod nó quản lý.
 + Ví dụ, thằng RC không thể nào match với pod mà có env=production và env=testing cùng lúc được, trong khi thằng RS có thể, 
  bằng cách chỉ định label selector như env=* 
 +  Ngoài ra, ta có thể dùng operators với thuộc tính matchExpressions -  Có 4 operators cơ bản là: In, NotIn, Exists, DoesNotExis
 kubectl apply -f hello-rs.yml
 kubectl get rs
 kubectl delete rs hello-rs