Kubernetes: 
+ Kubernetes là một nền tảng để quản lý, mở rộng các ứng dụng hoạt động dựa trên containers, giúp thuận lợi trong việc cấu hình và tự động triển khai ứng dụng một cách linh hoạt và tin cậy.
+ Kubernetes giúp chúng ta điều phối các container, nó đảm bảo tất cả các containers được lên lịch chạy trên các server(physical machine hoặc virtual machine).
+ Kubernetes còn giúp ta theo dõi hoạt động của các container, khi một container nào đó gặp lõi hoặc dừng hoạt động thì kubernetes sẽ tự động thay thế container đó.
+ Pod
   + Pod là đơn vị nhỏ nhất trong k8s chứa một hoặc nhiều container liên quan đến nhau.
   + Hay hiểu đơn giản là pod sẽ tạo ra môi trường chạy các container. 
   + Mỗi pod sẽ sở hữu một internal Ip riêng và có thể giao tiếp với nhau.
   + Địa chỉ IP này sẽ được thay đổi khi các pod được khởi tạo lại (re-creation). 
   + Thông thường một ứng dụng sẽ được chạy trên một pod.
   + Vì địa chỉ IP của pod được thay đổi mỗi khi được khởi tạo lại nên giả sử container db của ta bị lỗi khiến pod chứa 2 container db và app phải tiến hành khởi tạo lại 
   để thay thế cái cũ thì lúc này 2 pod sẽ bị mất kết nối.
    -->  Chính vì vậy ta sẽ có tiếp một khái niệm mới là service.
+ Service
   + Service được xác định dựa trên label, đại diện cho một entry point để truy cập vào ứng dụng.
   + Mỗi service có địa chỉ IP và port không đổi. 
   + Client có thể kết nối đến các IP và port của service, sau đó sẽ được điều hướng đến các pod để xử lý.
   + Quan trọng hơn hết là life cycle của service và pod không liên quan quan (kết nối) với nhau nên khi một pod bị crash (hoặc chết) thì service và IP của nó vẫn tồn tại.
   + Chúng ta có thể định nghĩa external service hoặc internal service tùy vào mục đích sử dụng. 
   + Khi browser request đến ứng dụng, lúc này ta sẽ sử dụng IP để kết nối (external service) nhưng url với những sản phẩm production sẽ có domain name 
    lúc này ta có tiếp một khái niệm là ingress.
+ Ingress
   + Ingress là thành phần dùng để điều hướng các yêu cầu trafic giao thức HTTP và HTTPS từ bên ngoài vào các dịch vụ bên trong Cluster. 
   + Request sẽ đi đến ingreass và chuyển tiếp đến các service.
+ Label
   + Label cung cấp meta data nhận dạng cho các object trong Kubernetes.
   + Label cho phép ta tổ chức và nhóm các object trong cluster. 
   + Một object có thể có nhiều label và một label có thể được gán cho nhiều object khác nhau (n-n). 
   + Ta có thể dùng label để lọc các đối tượng trong cluster một cách dễ dàng

+ ReplicaSet
  + ReplicaSet sẽ đảm bảo rằng ứng dụng của ta luôn chạy đúng loại và số lượng pod trong cluster.
  + Ví dụ như khi chạy webserver thay vì chỉ chạy 1 instance ta sẽ chạy 2 hoặc 3 instance đẻ đảm bảo ứng dụng hoạt động ổn định. 
  + Trong một trường hợp nào đó khi pod bị crash thì k8s sẽ tự động tạo lại đủ số lượng pod tùy vào ReplicaSet ta định nghĩa.

+ ConfigMap 
  + Khi cần cung cấp cấu hình trong quá trình runtime của container. 
  + Giả sử ta có ứng dụng laravel kết nới với database mysql ta cần một số config như DB_ADDRESS, DB_NAME, DB_PASSWORD, ... mà không cần can thiệp vào code. 
  + ConfigMap cung cấp dữ liệu dưới dạng key và value.

+ Secrets:
  + Cũng tương tự như ConfigMap nhưng dùng với nhưng dữ liệu nhạy cảm cần được bảo mật như API_TOKEN, DB_PASSWORD, ...
  + Sử dụng secrets cho phép ta tạo container mà không cần đóng gói dữ liệu nhảy cảm trong container. 
  + Ta có thể truyền ConfigMap và Secret thông qua mainfest file hoặc k8s API. 


Kubernetes Architecture
  + Khi deploy Kubernetes, chúng ta sẽ có một cluster.
  + Một Kubernetes cluster bao gồm một tập hợp các worker machine đợi gọi là nodes giúp ta chạy các ứng dụng đã được container hóa. 
  + Trong đó các node sẽ được cung cấp các tài nguyên như computing, memory, storage, networking.
  + Mỗi một cluster có ít nhất một worker node.
  
+ Node processes
  + Kubernetes nodes là máy ảo hay máy vật lý chạy kubernetes.
  + Các node này cần chạy Kubernetes và docker, và mỗi máy này là một docker host.
  +  Mỗi node có nhiều pod.

+ Master node
  + Master node là server điều khiển các máy worker chạy ứng dụng. Nó bao gồm 4 thành phần chính:
    + Kubernetes API Server: cung cấp API cho k8s cluster dùng để thiết lập và xác thực cấu hình cho object như pod, service, .... 
      Lập trình viên khi triển khai ứng dụng sẽ gọi đến API này.
    + Scheduler: Thành phần này lập lịch triển khai cho các ứng dụng, đặt các pod vào node dựa trên tài nguyên và điều kiện khác được định nghĩa.
    + Controler Manager: Thành phần đảm nhiệm phần quản lý các Worker, kiểm tra trạng thái các Worker sống hay chết, thực hiện những thay đổi đối với cluster sao cho phù hợp.
    + Etcd: cơ sở dữ liệu của Kubernetes, tất cả các thông tin của Kubernetes được lưu trữ ở đây.

+ Worker node: là server để chạy các ứng dụng. Nó bao gồm 3 thành phần chính:
    + Kubelet: là một agent chạy trên mỗi worker có trách nghiệm giám sát giao tiếp với master node và quản lý các pod.
    + Kube-proxy: quản lý network policy trên mỗi node, chuyển tiếp, traffic tới node dựa trên policy.
    + Container runetime: phần chịu trách nghiệm chạy các container.


+ Vấn đề: các cách deploy ứng dụng phổ biến

  + Chạy thẳng ứng dụng trên server: 
     + Ở cách này chúng ta chạy ứng dụng trên server vật lý. 
     + Điểm yếu của cách deploy này là không có cách nào định nghĩa ranh giới tài nguyên giữ các ứng dụng và nó sẽ gây ra vấn đề về phân bổ tài nguyên giữa các ứng dụng. 
     + Ví dụ khi nhiều ứng dụng chạy trên cùng server vật lý, nếu có một thằng sử dụng nhiều tài nguyên hơn và cứ tăng tài nguyên nó sử dụng
      (vì ta không có giới hạn) thì những thằng còn lại sẽ có ít tài nguyên để sử dụng, khiến các ứng dụng còn lại sẽ chạy chậm
     + Để giải quyết vấn đề với cách deploy này, ta chỉ có cách là tách những thằng ứng dụng khác qua một server vật lý khác

 + Chia server ra thành các máy ảo và chạy ứng dụng trên máy ảo đó:
    + Đây là một giải pháp để giải quyết vấn đề của cách chạy thẳng ứng dụng trên server.
    + Được gọi là virtualization, nó cho phép ta chạy nhiều máy ảo (Virtual Machines - VMs) trên cùng một server vật lý, mỗi máy ảo sẽ có file system, 
    hệ điều hành (OS), share CPU riêng.
    +  Và những ứng dụng của ta sẽ chạy trong các VM này. VM được định nghĩa có giới hạn tài nguyên, do đó sẽ không xảy ra vấn để một ứng dụng sẽ chạy tốn tài nguyên 
    vượt qua giới hạn VM và ảnh hưởng tới những ứng dụng nằm trong VM khác.
    +  Điểm yếu của cách deploy này là do VM được virtualize bằng cách copy cả OS và phần cứng (hardware),
     nên một server chỉ có thể tạo một số lượng nhỏ VM (4 hoặc 5 với các server bình thường)

  + Chạy ứng dụng bằng cách sử dụng container:
    + GIống như VM, container cũng là cách để virtualize ứng dụng, nó cũng có file system, os riêng, nhưng khác với VM, container chỉ copy OS mà không copy hardware, 
    + do đó cho phép ta có thể chạy nhiều ứng dụng trên cũng server vật lý, mỗi ứng dụng sẽ có môi trường riêng của nó. 
    + Với container việc phát triển và chạy ứng dụng của ta trên các OS khác nhau rất dễ dàng.

+ Vậy kubernetes giúp ta vấn đề gì?
   + Chạy ứng dụng bằng container sẽ giúp ta rất nhiều vấn đề:
   + Hãy thử tưởng tượng nếu số container ta lên tới hơn 1000 thì làm cách nào ta biết được một container nào đó sẽ thuộc về ứng dụng nào hoặc nó thuộc project nào?
   + Nếu ta muốn tăng performance của ứng dụng bằng cách cho nó chạy bằng 2 hoặc 3 container thì làm cách nào ta có thể dẫn request người dùng tới ứng dụng mà có 2 hoặc 3 container đó,
   + Ta sẽ chỉa tới container nào? Và nếu server vật lý của chúng ta bị sự cố và không thể chạy nữa thì sao? 
+ Kubernetes sẽ giúp chúng ta giải quyết những vấn đề này nhiều nhất có thể.
   + Với kubernetes chúng ta có thể group và quản lý container theo ứng dụng và project,
   + Nó cũng cung cấp tính năng Service Discovery and Load Balancing để chúng ta có thể dẫn request của ứng dụng tới đúng container, 
   + Và cũng có tính năng giúp ứng dụng của chúng ta high available nhất có thể, khi một server vật lý gặp sự cố, nó có thể chuyển container của ta sang server vật lý khác. 
   + Ngoài ra kubernetes còn nhiều tính năng khác như: auto scale resource, auto restart application when failure, zero downtime deployment, automated rollouts and rollbacks application, 

+ Kiến trúc của Kubernetes
  + Kubernetes cluster (một cụm bao gồm một master và một hoặc nhiều worker) bao gồm 2 thành phần (component) chính:
    + Master nodes (control plane)
    + Worker nodes
  + Master nodes bao gồm 4 thành phần chính là API server, controller manager, Scheduler, Etcd 
    + API server: thành phần chính để giao tiếp với các thành phần khác
    + Controller manager: gồm nhiều controller riêng cụ thể cho từng resource và thực hiện các chứng năng cụ thể cho từng thằng resource trong kube như create pod, create deployment, v...v...
    + Scheduler: schedules ứng dụng tới node nào
    + Etcd: là một database để lưu giữ trạng thái và resource của cluster
 + Master node chỉ có nhiệm vụ control state của cluster, nó không có chạy ứng dụng trên đó, ứng dụng của chúng ta sẽ được chạy trên worker node.
 + Worker node gồm 3 thành phần chính như:
    + Container runtime (docker, rkt hoặc nền tảng khác): chạy container
    + Kubelet: giao tiếp với API server và quản lý container trong một worker node
    + Kubernetes Service Proxy (kube-proxy): quản lý network và traffic của các ứng dụng trong woker node

+ Kubernetes Pod là gì?
   + Pod là thành phần cơ bản nhất để deploy và chạy một ứng dụng, được tạo và quản lý bởi kubernetes.
   + Pod được dùng để nhóm (group) và chạy một hoặc nhiều container lại với nhau trên cùng một worker node,
    những container trong một pod sẽ chia sẻ chung tài nguyên với nhau.
   + Thông thường chỉ nên run Pod với 1 container 
 
+ Vậy tại sao là lại dùng Pod để chạy container, sao không chạy container trực tiếp? 
   + Kubernetes Pod như một wrapper của container, cung cấp cho chúng ta thêm nhiều chức năng để quản lý và chạy một container, 
   giúp container của ta chạy tốt hơn là chạy container trực tiếp, như là group tài nguyên của container, check container healthy và restart,
    chắc chắn ứng dụng trong container đã chạy thì mới gửi request tới container đó, cung cấp một số lifecycle để ta có thể thêm hành động vào Pod khi Pod chạy hoặc shutdown,...
   + Kubernetes sẽ quản lý Pod thay vì quản lý container trực tiếp

docker build . -t 080196/hello-kube
kubectl apply -f hello-kube.yml
kubectl get pod
kubectl describe pod <tên-pod>
kubectl logs <container-id>
kubectl delete pod hello-kube

+ Để test Pod, ta phải expose traffic của Pod để nó có thể nhận request trước, vì hiện tại Pod của chúng ta đang chạy trong local cluster và không có expose port ra ngoài
Có 2 cách để expose port của pod ra ngoài:
  + Service resource 
  + kubectl port-forward: kubectl port-forward pod/hello-kube 3000:3000

+ Tổ chức pod bằng cách sử dụng labels:
  + Dùng label là cách để chúng ta có thể phân chia các pod khác nhau tùy thuộc vào dự án hoặc môi trường.
  + Ví dụ công ty của chúng ta có 3 môi trường là testing, staging, production, nếu chạy pod mà không có đánh label thì sẽ rất khó để biết pod nào thuộc môi trường nào
  + Labels là một thuộc tính cặp key-value mà chúng ta gán vào resource ở phần metadata, ta có thể đặt tên key và value với tên bất kì.

kubectl get pod --show-labels
kubectl get pod -L enviroment  
kubectl get pod -l enviroment=production
kubectl delete -f hello-kube.yml


Phân chia tài nguyên của kubernetes cluster bằng cách sử dụng namespace

+ Ta đã biết cách chạy pod và dùng labels để tổ chức pod, nhưng ta chưa có phân chia tài nguyên giữa các môi trường và dự án khác nhau.
+ Ví dụ trong một dự án thì ta muốn tài nguyên của production phải nhiều hơn của testing, thì ta làm thế nào? Chúng ta sẽ dùng namespace
+ Namespace là cách để ta chia tài nguyên của cluster, và nhóm tất cả những resource liên quan lại với nhau, 
bạn có thể hiểu namespace như là một sub-cluster. 
+ Đầu tiên chúng ta list ra toàn bộ namespace: kubectl get ns
+ Ta sẽ thấy có vài namespace đã được tại bởi kube: default,kube-node-lease,kube-public,kube-system
   + default là namespace chúng ta đang làm việc với nó, khi ta sử dụng câu lệnh kubectl get để hiển thị resource, 
    nó sẽ hiểu ngầm ở bên dưới là ta muốn lấy resource của namespace mặc định. 
   + Ta có thể chỉ định resource của namespace chúng ta muốn bằng cách thêm option --namespace 

+ Namespace default là namespace mặc định cho các tài nguyên nếu bạn không chỉ định namespace cụ thể khi tạo hoặc truy vấn các tài nguyên. 
+ Điều này có nghĩa là nếu bạn không cung cấp namespace trong các lệnh kubectl, các tài nguyên sẽ được tạo ra hoặc tìm kiếm trong namespace default.
+ Khi bạn tạo các tài nguyên như Pod, Service, Deployment, hoặc ConfigMap mà không chỉ định namespace, chúng sẽ được tạo trong namespace default
+ kubectl get pods | kubectl get pods --namespace default

kube-system:
   + Namespace này chứa các tài nguyên và dịch vụ quan trọng cho việc vận hành và quản lý cluster Kubernetes.
   + Các thành phần hệ thống như kube-apiserver, kube-controller-manager, kube-scheduler, và các addon như CoreDNS hoặc các công cụ giám sát thường nằm trong namespace này.
   + Ví Dụ: Các Pod và Service quản lý các thành phần hệ thống của Kubernetes thường được triển khai ở đây.
kube-public:
  +  Namespace này được sử dụng để lưu trữ các tài nguyên có thể truy cập công khai trong cluster.
  +  Ví dụ, nó thường chứa các ConfigMap có thể được truy cập công khai bởi bất kỳ ai trong cluster.
  +  Namespace này có thể dùng để chia sẻ thông tin công khai giữa các thành phần trong cluster.
  + Ví Dụ: ConfigMap chứa thông tin về các tài nguyên công khai hoặc cấu hình có thể được truy cập bởi các thành phần khác trong cluster.
kube-node-lease:
 +  Namespace này chứa các đối tượng Lease được sử dụng để theo dõi trạng thái của các node trong cluster.
 +  Lease là một đối tượng đặc biệt giúp Kubernetes duy trì trạng thái của các node và cải thiện khả năng phục hồi.
 + Ví Dụ: Các đối tượng Lease trong namespace này giúp kubelet và các thành phần hệ thống khác theo dõi sức khỏe và trạng thái của các node.


kubectl get pod --namespace kube-system
kubectl describe pod <tên-pod> --namespace kube-system
kubectl create ns testing
kubectl create ns production
kubectl create ns staging
kubectl apply -f hello-cube.yml
kubectl get pods
kubectl get pod -n testing
kubectl delete pod hello-kube-testing -n testing
kubectl delete ns testing

+ Các Hạn Chế Khi Chạy Pod Trực Tiếp
 + Khả Năng Mở Rộng: Khi chạy Pod trực tiếp, bạn phải quản lý và theo dõi từng Pod một cách thủ công. Điều này làm giảm khả năng mở rộng và linh hoạt của hệ thống.
 + Khả Năng Tự Phục Hồi: Nếu một Pod bị lỗi hoặc bị chết, Kubernetes không tự động khởi động lại Pod đó. Điều này đòi hỏi sự can thiệp thủ công hoặc viết các script phức tạp để tự phục hồi.
 + Quản Lý Số Lượng Pod: Quản lý số lượng Pod mong muốn một cách thủ công không hiệu quả và dễ mắc lỗi. Điều này đặc biệt khó khăn khi số lượng Pod cần mở rộng hoặc thu hẹp theo tải công việc.
 + Khả Năng Kiểm Soát Tình Trạng: Không có cơ chế tự động để đảm bảo rằng số lượng Pod luôn đúng với yêu cầu. Việc này có thể dẫn đến tình trạng quá tải hoặc thiếu hụt tài nguyên.

--> Giải pháp: ReplicationControllers and other controller:
Như chúng ta đã biết pod là thành phần cơ bản nhất để deploy application, nhưng trong thực tế ta sẽ không chạy pod trực tiếp như ở trên,
vì nó sẽ gặp nhiều hạn chế, mà chúng ta sẽ tạo những resource khác như ReplicationControllers hoặc ReplicaSets, và nó sẽ tự động tạo và quản lý pod

+ ReplicationControllers(RC) là gì?
  + ReplicationControllers là một resource mà sẽ tạo và quản lý pod, và chắc chắn là số lượng pod nó quản lý không thay đổi và kept running.
  + ReplicationControllers sẽ tạo số lượng pod bằng với số ta chỉ định ở thuộc tính replicas và quản lý pod thông qua labels của pod

+ Tại sao ta nên dùng ReplicationControllers để chạy pod?
  + Chúng ta đã biết pod nó sẽ giám sát container và tự động restart lại container khi nó fail
  + Vậy trong trường hợp  worker node(bọc ngoài Pod) của chúng ta fail thì sẽ thế nào? 
    --> Pod nó sẽ không thể chạy nữa, và application của chúng ta sẽ downtime với người dùng

+ Nếu chúng ta chạy cluster với hơn 1 worker node, RC sẽ giúp chúng ta giải quyết vấn đề này.
+ Vì RC sẽ chắc chắn rằng số lượng Pod mà nó tạo ra không thay đổi
+ Ví dụ khi ta tạo một thằng RC với số lượng replicas = 1, RC sẽ tạo 1 Pod và giám sát nó,
khi một thằng worker node die, nếu Pod của thằng RC quản lý có nằm trong worker node đó, 
thì lúc này thằng RC sẽ phát hiện ra là số lượng Pod của nó bằng 0, và nó sẽ tạo ra thằng Pod ở một worker node khác để đạt lại được số lượng 1
+ Luồng: Start --> Find Pods matching with Label Selector --> Compare Matched with Pod Count --> Too Few: Create additional Pod
                                                                |                                        |
                                                                | --> Too many: Delete Pods ------------ Start

+ Sử dụng RC để chạy Pod sẽ giúp ứng dụng của chúng ta luôn luôn availability nhất có thể. 
+ Ngoài ra ta có thể tăng performance của ứng dụng bằng cách chỉ định số lượng replicas trong RC để RC tạo ra nhiều pod chạy cùng một version của ứng dụng.
+ Ví dụ ta có một webservice, nếu ta chỉ deploy một pod để chạy ứng dụng, thì ta chỉ có 1 container để xử lý request của user,
nhưng nếu ta dùng RC và chỉ định replicas = 3, ta sẽ có 3 pod chạy 3 container của ứng dụng, và request của user sẽ được gửi tới 1 trong 3 pod này,
giúp quá trình xử lý của chúng ta tăng gấp 3 lần

Tại Sao Cần Nhiều Pod?
Tăng Tính Sẵn Sàng (Availability):
  + Khi chỉ có một Pod, nếu Pod đó gặp sự cố (chết, lỗi, hoặc bị ngừng hoạt động), toàn bộ dịch vụ của bạn sẽ ngừng hoạt động. 
  + Sử dụng RC hoặc ReplicaSet với nhiều Pod giúp đảm bảo rằng luôn có sẵn một số lượng Pod nhất định để xử lý yêu cầu.
Cải Thiện Hiệu Suất (Performance):
  + Với nhiều Pod, bạn có thể phân tán tải giữa các Pod, giúp tăng khả năng xử lý đồng thời và giảm độ trễ. 
  + Điều này đặc biệt quan trọng đối với các ứng dụng web hoặc các dịch vụ cần xử lý nhiều yêu cầu cùng lúc.

+ Cấu trúc của một file config RC sẽ gồm 3 phần chính như sau:
  + label selector: sẽ chỉ định pod nào sẽ được RC giám sát
  + replica count: số lượng pod sẽ được tạo
  + pod template: config của pod sẽ được tạo
kubectl apply -f hello-rc.yml
kubectl get rc  # Nếu số lượng ở cột READY bằng với số lượng DESIRED thì chúng ta đã chạy RC thành công
kubectl get pod # tên của pod được tạo ra bởi RC sẽ theo kiểu <replicationcontroller name>-<random>
kubectl delete pod hello-rc-c6l8k
kubectl get pod # Auto tạo 1 Pod mới

Thay đổi template của pod
Bạn có thể thay đổi template của pod và cập nhật lại RC, nhưng nó sẽ không apply cho những thằng pod hiện tại, 
muốn pod của bạn cập nhật template mới, bạn phải xóa hết pod để RC tạo ra pod mới, hoặc xóa RC và tạo lại
Khi  xóa RC thì những thằng pod nó quản lý cũng sẽ bị xóa theo

kubectl delete rc hello-rc

ReplicaSets(RS):
 + Đây là một resource tương tự như RC, nhưng nó là một phiên bản mới hơn của RC và sẽ được sử dụng để thay thế RC. 
 + Chúng ta sẽ dùng ReplicaSets (RS) để deploy pod thay vì dùng RC
 + RS và RC sẽ hoạt động tương tự nhau. Nhưng RS linh hoạt hơn ở phần label selector, trong khi label selector 
 thằng RC chỉ có thể chọn pod mà hoàn toàn giống với label nó chỉ định, thì thằng RS sẽ cho phép dùng một số expressions hoặc matching để chọn pod nó quản lý.
 + Ví dụ, thằng RC không thể nào match với pod mà có env=production và env=testing cùng lúc được, trong khi thằng RS có thể, 
  bằng cách chỉ định label selector như env=* 
 +  Ngoài ra, ta có thể dùng operators với thuộc tính matchExpressions -  Có 4 operators cơ bản là: In, NotIn, Exists, DoesNotExis
 kubectl apply -f hello-rs.yml
 kubectl get rs
 kubectl delete rs hello-rs


 Sử dụng DaemonSets để chạy chính xác một pod trên một worker node
 Đây là một resource khác của kube, giống như RS, nó cũng sẽ giám xác và quản lý pod theo lables.
 Nhưng thằng RS thì pod có thể deploy ở bất cứ node nào, và trong một node có thể chạy mấy pod cũng được.
 Còn thằng DaemonSets này sẽ deploy tới mỗi thằng node một pod duy nhất, và chắc chắn có bao nhiêu node sẽ có mấy nhiêu pod, nó sẽ không có thuộc tính replicas
 Ứng dụng của thằng DaemonSets này sẽ được dùng trong việc logging và monitoring.
 Lúc này thì chúng ta sẽ chỉ muốn có một pod monitoring ở mỗi node. 

 kubectl label nodes <your-node-name> disk=ssd: đánh label vào trong một thằng woker node bằng cách sử dụng câu lệnh

 + Services: expose traffic cho Pod


Kubernetes Services là gì?
  + Là một resouce sẽ tạo ra một single, constant point của một nhóm Pod phía sau nó.
  + Mỗi service sẽ có một địa chỉ IP và port không đổi, trừ khi ta xóa nó đi và tạo lại. 
  + Client sẽ mở connection tới service, và connection đó sẽ được dẫn tới một trong những Pod ở phía sau.
  
Vậy service giúp ta những vấn đề gì? Mỗi thằng Pod nó cũng có địa chỉ IP riêng của nó, 
sao ta không gọi thẳng nó luôn mà thông qua service chi cho mất công?

  + Vì địa chỉ IP của pod được thay đổi mỗi khi được khởi tạo lại nên giả sử container db của ta bị lỗi khiến pod chứa 2 container db và app phải tiến hành khởi tạo lại 
   để thay thế cái cũ thì lúc này 2 pod sẽ bị mất kết nối.
    -->  Chính vì vậy ta sẽ có tiếp một khái niệm mới là service.
   + Service được xác định dựa trên label, đại diện cho một entry point để truy cập vào ứng dụng.
   + Mỗi service có địa chỉ IP và port không đổi. 
   + Client có thể kết nối đến các IP và port của service, sau đó sẽ được điều hướng đến các pod để xử lý.
   + Quan trọng hơn hết là life cycle của service và pod không liên quan quan (kết nối) với nhau nên khi một pod bị crash (hoặc chết) thì service và IP của nó vẫn tồn tại.
   + Chúng ta có thể định nghĩa external service hoặc internal service tùy vào mục đích sử dụng. 
   + Khi browser request đến ứng dụng, lúc này ta sẽ sử dụng IP để kết nối (external service) nhưng url với những sản phẩm production sẽ có domain name 
    lúc này ta có tiếp một khái niệm là ingress.
  
  + Pods are ephemeral(tạm thời,ko bền vững): 
     + Nó sẽ được tạo ra, bị xóa, và thay thế bằng một thằng khác bất cứ lúc nào
     + Khi một woker node die, Pod trên worker node đó cũng sẽ die theo, và một Pod mới sẽ được tạo ra trên woker node khác.
     + Khi tạo thằng pod mới tạo ra, nó sẽ có một IP khác với thằng cũ.
     + Nếu ta dùng IP của Pod để tạo connection tới client thì lúc Pod được thay thế với IP khác thì ta phải update lại code

Multiple Pod run same application
Có nghĩa là ta sẽ có nhiều pod đang chạy một ứng dụng của chúng ta để tăng performance. 
Ví dụ khi ta dùng ReplicaSet với replicas = 3, nó sẽ tạo ra 3 Pod. Vậy làm sao ta biết được nên gửi request tới Pod nào?
Thì để giải quyết những vấn để trên thì Kubernetes cung cấp cho chúng ta Services để quản lý connection

Làm sao Service biết được nó sẽ chọn Pod nào để quản lý connection tới những Pod đó?
Services cũng sẽ sử dụng label selectors để chọn Pod mà nó quản lý connection.

Service sẽ có 4 loại cơ bản là:
  + ClusterIP
  + NodePort
  + ExternalName
  + LoadBalancer

+ ClusterIP
  + Đây là loại service sẽ tạo một IP và local DNS mà sẽ có thể truy cập ở bên trong cluster, không thể truy cập từ bên ngoài,
  + Được dùng chủ yếu cho các Pod ở bên trong cluster dễ dàng giao tiếp với nhau.

kubectl get svc

+ Redis của sẽ có địa chỉ truy cập như sau redis://10.102.135.144:6379 - hostname: 10.102.135.144 - dùng địa chỉ này để các ứng ta deploy về sau truy cập được tới redis host.
+ Các ứng dụng đã chạy sẵn, để kết nối tới host này truy cập redis host thằng IP, ta có thể truy cập thông qua DNS, kubernes có cung cấp cho chúng ta một local DNS bên trong cluster, 
 giúp chúng ta có thể connect được tới host ta muốn thông qua DNS. 
 --> Ta có thể connect redis với địa chỉ sau redis://redis:6379, với host name là tên của Service chúng ta đặt trong trường metadata.
 
kubectl run hello-redis --image=080196/hello-redis
kubectl delete pod hello-redis
kubectl delete -f hello-service.yaml


ClusterIP giúp các ứng dụng deploy trong cluster của ta giao tiếp với nhau dễ dàng hơn nhiều. 
Còn nếu chúng ta muốn client từ bên ngoài có thể truy cập vào ứng dụng của chúng ta thì sao?
Có 3 cách đó là dùng NodePort, LoadBalancer (hỗ trợ clound), Ingress.

+ NodePort: 
Đây là cách đầu tiên để expose Pod cho client bên ngoài có thể truy cập vào được Pod bên trong cluster.
Giống như ClusterIP, NodePort cũng sẽ tạo endpoint có thể truy cập được bên trong cluster bằng IP và DNS,
đồng thời nó sẽ sử dụng một port của toàn bộ worker node để client bên ngoài có thể giao tiếp được với Pod của chúng ta thông qua port đó. 
NodePort sẽ có range mặc định từ 30000 - 32767.

kubectl apply -f hello-nodeport.yml
kubectl inspect hello-rs-lsrb6 
curl http://192.168.49.2:31000

LoadBalancer(NginX)
Khi bạn chạy kubernetes trên cloud, nó sẽ hỗ trợ LoadBalancer Service, nếu bạn chạy trên môi trường không có hỗ trợ LoadBalancer thì bạn không thể tạo được loại Service này.
Khi bạn tạo LoadBalancer Service, nó sẽ tạo ra cho chúng ta một public IP, mà client có thể truy cập Pod bên trong Cluster bằng địa chỉ public IP này. 


Ingress:
Ingress là một resource cho phép chúng ta expose HTTP and HTTPS routes từ bên ngoài cluster tới service bên trong cluster của chúng ta.
Ingress sẽ giúp chúng ta gán một domain thực tế với service bên trong cluster.

Tóm lại: Đóng gói application bằng container, nhóm chúng lại bằng Pod, rồi dùng ReplicaSet để chạy Pod để application của chúng ta high availability nhất có thể,
dùng Service để mở kết nối của Pod ra bên ngoài.

Cập nhật một ứng dụng đang chạy trong pods
Bắt đầu với một ví dụ là ta đang có một ứng dụng đang chạy, ta deploy nó bằng ReplicaSet, với replicas = 3, nó sẽ chạy 3 Pod đằng sau,
và ta deploy một Service để expose traffic của nó ra cho client bên ngoài.

Bây giờ các dev trong team đã viết xong tính năng mới, ta build lại image với code mới, và ta muốn update lại các Pod đang chạy này với image mới.
Ta sẽ làm như thế nào? Thì trong quá trình deploy, sẽ có rất nhiều chiến lược để làm, nhưng có 2 cách thông dụng nhất là: Recreate and RollingUpdate

Recreate
  + Ở cách deploy này, đầu tiên là sẽ xóa toàn bộ phiên bản (version) cũ của ứng dụng trước, sau đó ta sẽ deploy một version mới lên.
  + Đối với kubernes thì đầu tiên ta sẽ cập nhật Pod template của ReplicaSet, sau đó ta xóa toàn bộ Pod hiện tại, để ReplicaSet tạo ra Pod với image mới.
Với cách deploy này thì quá trình deploy quá dễ dàng, nhưng ta sẽ gặp một vấn đề rất lớn, đó là ứng dụng của chúng ta sẽ downtime với client, client không thể request tới ứng dụng của ta trong quá trình version mới được deploy lên.

Với những hệ thống ít client thì dù bạn downtime 1 phút 2 phút hoặc 1 tiếng cũng không ảnh hưởng nhiều lắm, 
nhưng với những hệ thống với số lượng request lớn tầm 1000-3000 request trên giây, đặt biệt là với hệ thống ngân hàng thì quá trình downtime dù chỉ 1s thì cũng không được.
Nên mới sinh ra cách deploy thứ hai là RollingUpdate

RollingUpdate
Ở cách này, ta sẽ deploy từng version mới của ứng dụng lên, chắc chắn rằng nó đã chạy, ta dẫn request tới version mới của ứng dụng này, 
lặp lại quá trình này cho tới khi toàn bộ version mới của ứng dụng được deploy và version cũ đã bị xóa.
Đối với kubernetes, ta sẽ lần lượt xóa từng Pod và ReplicaSet sẽ tạo Pod mới 

Thì ở cách deploy này, điểm mạnh là ta sẽ giảm thời gian downtime của ứng dụng đối với client,
còn điểm yếu là ta sẽ có version mới và version cũ của ứng dụng chạy chung một lúc. 
Và khó nhất là ta phải viết script để thực hiện quá trình này, test script này chạy đúng không, rất mất thời gian và công sức. 
Với các hệ thống lớn thì để viết một cái script test được quá trình deploy này thì không dễ chút nào.

Để chọn cách deploy nào cho ứng dụng thì còn tùy vào tình huống và nhu cầu, nếu ứng dụng ta có thể chạy 
nhiều version của ứng dụng cùng lúc không ảnh hưởng thì ta sẽ chọn RollingUpdate. 

Còn nếu ứng dụng chúng ta downtime không ảnh hưởng gì, thì ta sẽ cách Recreate để deploy.
Còn cách một cách nữa là không có downtime và không có nhiều version của ứng dụng chạy cùng một lúc nữa là Bule-Green update



Nếu ta chỉ dùng những resource bình thường, thì vấn đề đầu tiên ta gặp phải là quá trình cập nhật version mới của ứng dụng 
và cần phải script để thực hiện một số thao tác như xóa Pod cũ. 
Vấn đề thứ hai ta sẽ gặp là ta phát hiện version mới của chúng ta chạy sai hoặc có bug, ta muốn lùi lại phiên bản trước đó thì làm sao?


Lùi lại phiên bản trước của ứng dụng
Thì ở đây chúng ta sẽ có cách là fix bug, build image mới, rồi thực hiện lại cách depoy là Recreate hoặc RollingUpdate đối với những lỗi không cần gấp lắm và không lớn lắm. 
Còn đối với lỗi bự và ảnh hưởng nhiều tới client thì ta thường sẽ revert lại code trên git, sau đó ta build image, thực hiện deploy lại.

Đối với kubernetes, chúng ta dùng container chạy ứng dụng thì chỉ cần update lại version của image trong Pod template bằng image trước đó, 
rồi dùng cách Recreate hoặc RollingUpdate để deploy lại Pod là xong, không cần revert code hoặc fixbug ngay lập tức. 
Dù là cách nào thì cũng sẽ tốn nhiều thời gian để thực hiện và chạy CI/CD lại.

Để giải quyết những vấn đề trên thì kubernetes cung cấp một resource là Deployment.

Deployment là gì?
Deployment là một resource của kubernetes giúp ta trong việc cập nhật một version mới của úng dụng một cách dễ dàng, 
nó cung cấp sẵn 2 strategy để deploy là Recreate và RollingUpdate, tất cả đều được thực hiện tự động bên dưới, và các version được deploy sẽ có một histroy ở đằng sau, 
ta có thể rollback and rollout giữa các phiên bản bất cứ lúc nào mà không cần chạy lại CI/CD.

Khi ta tạo một Deployment, nó sẽ tạo ra một ReplicaSet bên dưới, và ReplicaSet sẽ tạo Pod. 
Luồng như sau Deployment tạo và quản lý ReplicaSet -> ReplicaSet tạo và quản lý Pod -> Pod run container.

docker build . -t 080196/hello-app:v1
kubectl apply -f hello-deploy.yml
kubectl delete pods --all
kubectl get rs
kubectl delete rs --all 
kubectl get deploy
kubectl get svc
kubectl describe pod hello-app   192.168.49.2
curl http://192.168.49.2:31000  - Hello application v1

Vậy là deployment của chúng ta đã chạy thành công.
Bây giờ ta sẽ tiến hành update lại ứng dụng đang chạy trong Pod. 
Ứng dụng của Pod mới sẽ có image là 080196/hello-app:v2
docker build . -t 080196/hello-app:v2

Để update lại ứng dụng trong Pod với Deployment. Ta chạy câu lệnh sau:

kubectl set image deployment hello-app hello-app=080196/hello-app:v2

Cấu trúc câu lệnh kubectl set image deployment <deployment-name> <container-name>=<new-image>

Kiểm tra qua trình update đã xong chưa:

kubectl rollout status deploy hello-app
curl http://192.168.49.2:31000  - Hello application v2

Nếu ở đây đã in ra được Hello application v2 thì ứng dụng của chúng ta đã cập nhật được version mới.
Như các bạn thấy thì quá trình deploy một version của ứng dụng cực kì đơn giản nếu chúng ta xài Deployment.